<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<!--<meta  name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes"/>-->
<meta http-equiv="Content-Type" content="text/html; charset=gb2312"/>
<link rel="stylesheet" href="Files/jemdoc.css" type="text/css" />

<link rel="shortcut icon" href="./Files/favicon.ico">
<title>Zhuo Su</title>
</head>
 


<body> 




<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<h1>Zhuo Su 苏 卓</h1></A>
<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/zhousu1.gif" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"></a><br />
<i> I am a final-year Master in Department of Automation, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, supervised by <a href="http://media.au.tsinghua.edu.cn/index/team/qhdai.html">Prof. Qionghai Dai</a> and
    <a href="http://luvision.net/">Prof. Lu Fang</a>. Meanwhile, I work closely with <a href="https://liuyebin.com/">Prof. Yebin Liu</a> and <a href="https://www.xu-lan.com/index.html">Lan Xu</a>. My research focuses on computer vision
    and graphics, especially human performance capture, 3D reconstruction and so on.
</a></i>
<br />
<br />
Email: su-z18@mails.tsinghua.edu.cn / suzhuo13@gmail.com 
<br />
<br />
<class="staffshortcut">
 <A HREF="#Background">Background</A> | 
 <A HREF="#Interests">Interests</A> | 
 <A HREF="#Research">Research</A> | 
 <A HREF="#Awards">Awards</A>|
 <A HREF="#Skills">Skills</A>|
 <a href="./Files/cv_zhuosu.pdf">CV</a>
<br />
<br />
 

</td></tr></table>


 

<A NAME="Background"><h2>Background</h2></A>
<ul>
    <font style="line-height:1.8;">
        <b>M.S.</b>,&nbsp Department of Automation, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, Beijing, China.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2018.08-2021.06 &nbsp;&nbsp;&nbsp;&nbsp;
        <br />
        GPA: 3.89/4.0 (GPA ranking: top 5%)
        <br />
        <b>B.E.</b>,&nbsp Department of Automation, <a href="http://english.neu.edu.cn/">Northeastern University</a>, Shenyang, China.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2014.10-2018.06 &nbsp;&nbsp;&nbsp;&nbsp;
        <br />
        GPA: 4.18/5.0 (GPA ranking: 5/276; Comprehensive ranking: 1/276)
    </font>
</span></ul>
<br />


 
<A NAME="Interests"><h2>Interests</h2></A>
    &nbsp;&nbsp;&nbsp;&nbsp; My research interests include computer vision and comptuter graphics. Currently, I focus on the following topics:
<ul>
<li>Human Performance Capture</li>
<Li>Reconstruction of Dynamic Scenes</Li>
<li>Photorealistic 3D Modeling</li>
</ul>
<br />




<A NAME="Research"><h2>Research</h2></A>
<font size="3"> 
<ul>
<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/robustfusion.jpg" alt="" height="180px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"></a>
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span> 

    <b>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RobustFusion: Human Volumetric Capture with Data-driven Visual Cues using a RGBD Camera
        <br />
    </b>
    <b>Zhuo Su</b>, <a href="https://www.xu-lan.com/index.html">Lan Xu</a>, <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, <a href="https://ytrock.com/">Tao Yu</a>, <a href="https://liuyebin.com/">Yebin Liu</a>, <a href="http://luvision.net/">
    Lu Fang</a>
    <br />
    <b><i>European Conference on Computer Vision 2020 (ECCV 2020 Spotlight).</i></b>
    <br /><br />
    We introduce a robust human volumetric capture approach combined with various data-driven visual cues using a Kinect, which outperforms existing state-of-the-art approaches significantly.
    <br />
    [<a href="./Files/Rofusion.pdf">Paper</a>]
    [<a href="./Projects/RobustFusion_page/index.html">Project page</a>]
</a></span>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/unfusion.jpg" alt="" height="150px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"></a>
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span> 

<b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UnstructuredFusion: Realtime 4D Geometry and Texture Reconstruction using Commercial RGBD Cameras</b>
    <br />
    <a href="https://www.xu-lan.com/index.html">Lan Xu</a>, <b>Zhuo Su</b>, <a href="https://sites.google.com/view/lhanaf/%E9%A6%96%E9%A1%B5">Lei Han</a>, <a href="https://ytrock.com/">Tao Yu</a>, <a href="https://liuyebin.com/">Yebin Liu</a>, <a href="http://luvision.net/">Lu Fang</a>
    <br />
    <b><i>IEEE Transactions on Pattern Analysis and Machine Intelligence 2019 (TPAMI 2019).</i></b>
    <br /><br />
    We propose UnstructuredFusion, which allows realtime, high-quality, complete reconstruction of 4D textured models of human performance via only three commercial RGBD cameras.
    <br />
    [<a href="./Files/Unfusion.pdf">Paper</a>]
    [<a href="./Projects/UnstructedFusion_page/index.html">Project page</a>]

</a></span>
</p>
</td></tr></table>



<table class="imgtable"><tr><td>
    <a href="./"><img src="./Files/robustfusionplus.jpg" alt="" height="190px" /></a>&nbsp;</td>
    <td align="left"><p><a href="./"></a>
    <p style="text-indent: -1.6rem;margin-left: 0rem;">
    <span> 
    
    <b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RobustFusion: Robust Volumetric Performance Reconstruction under Human-object Interactions from Monocular RGBD Stream</b>
        <br />
        <b>Zhuo Su</b>, <a href="https://www.xu-lan.com/index.html">Lan Xu</a>, <a>Dawei Zhong</a>, <a>Zhong Li</a>, <a>Fan Deng</a>, <a>Shuxue Quan</a>, <a href="http://luvision.net/">Lu Fang</a>
        <br />
        <b><i>TPAMI 2021 Under Review.</i></b>
        <br /><br />
        <!-- We propose UnstructuredFusion, which allows realtime, high-quality, complete reconstruction of 4D textured models of human performance via only three commercial RGBD cameras. -->
        we propose a robust volumetric performance reconstruction system for human-object interaction scenarios using only a single RGBD sensor, which combines various data-driven visual and interaction cues to handle the complex interaction patterns and severe occlusions. 
        <br />
        [<a href="./Projects/RobustFusion_plus_page/RobustFusionPlus.pdf">Paper</a>]
        [<a href="./Projects/RobustFusion_plus_page/index.html">Project page</a>]
    
    </a></span>
    </p>
    </td></tr></table>


</ul>
<br />
 



 
 
 

<A NAME="Projects"><h2>Early work</h2></A>
<font size="3"> 
<ul>
    <li> Wen Fei, <b>Zhuo Su*</b>, Changfu Zhou,
         “Artificial landmark design and detection using hierarchy information for UAV localization and landing”, 
    Chinese Control And Decision Conference 2017 (CCDC 2017),
          [<a href="./Files/UAV.pdf">Paper</a>]
    </li>

    <li>Haina Wu, <b>Zhuo Su</b>, Kai Luo, Qi Wang, Xianzhong Cheng
        "Exploration and Research on the Movement of Magnus Glider”, Physical Experiment of College, 2015 (5): 2,
        [<a href="./Files/Glider.pdf">Paper</a>]
    </li>
</ul>
<br />


<!-- awards -->
<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>Excellent Bachelor Thesis Award, Northeastern University, 2018</li>
<li>Outstanding Graduate of Liaoning Province, Liaoning Province, 2018</li>
<li>National Scholarship, Ministry of Education, 2018</li>
<li>Excellence Award for National Undergraduate Innovation Program, Northeastern University, 2017</li>
<li>City's Excellent Undergraduate, Shenyang City, 2017</li>
<li>Mayor's Scholarship, Shenyang City, 2017</li>
<li>Top Ten Excellent Undergraduate (10 / the whole university), Northeastern University, 2017</li>
<li>Honorable Mention of American Mathematical Contest in Modeling, COMAP, 2017</li>
<li>Second Prize of National Undergraduate Mathematical Contest in Modeling, CSIAM, 2016</li>
<li>First Prize of Provincial Undergraduate Mathematical Contest in Modeling, Liaoning Province, 2016</li>
<li>2x Second Prize of Electronic Design Contest, Education Department of Liaoning Province, 2015-2016</li>
<li>4x First Class Scholarships, Northeastern University, 2015-2018</li>
</ul>
</font>
<br />

<A NAME="Skills"><h2>Skills</h2></A>
&nbsp;&nbsp;&nbsp;&nbsp; C & C++(OpenCV, OpenGL, CUDA, Eigen, ...), Python(Pytorch), Matlab, LaTeX, ...
<br />
<br />

<!--<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5vmure15sa4&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>
-->
</body>
</html>
